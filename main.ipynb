{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 21:16:28.160467: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from keras import Sequential, Input\n",
    "from keras.layers import RandomFlip, RandomContrast, RandomRotation, RandomZoom, Rescaling\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Conv2D, BatchNormalization, Dropout, Flatten\n",
    "from keras.applications import EfficientNetV2L as base\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import SparseCategoricalCrossentropy as scc\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "DEVICES AVAILABLE: 1\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('DEVICES AVAILABLE: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10002 files belonging to 2 classes.\n",
      "Using 8002 files for training.\n",
      "Found 10002 files belonging to 2 classes.\n",
      "Using 2000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "image_size = 256\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "lr_init = .002\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  '/Users/dragxn/Desktop/projhealth/Oral Cancer',\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(image_size, image_size),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  '/Users/dragxn/Desktop/projhealth/Oral Cancer',\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(image_size, image_size),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Normal', 'Squamous Cell Carcinoma']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "val_batches = tf.data.experimental.cardinality(val_ds)\n",
    "test_ds = val_ds.take(val_batches // 2)\n",
    "val_ds = val_ds.skip(val_batches // 2)\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', patience=10, min_delta=0.001, restore_best_weights=True)\n",
    "def create_model(base_model):\n",
    "    input = Input(shape=(image_size, image_size, 3))\n",
    "    x = RandomFlip('horizontal')(input)\n",
    "    x = RandomRotation(0.2)(x)\n",
    "    x = RandomZoom(0.2,0.2)(x)\n",
    "    x = RandomContrast(0.2)(x)\n",
    "    b_model = base_model(x)\n",
    "    flatten = Flatten()(b_model)\n",
    "    x = Dense(1024,activation='relu')(flatten)\n",
    "    norm = BatchNormalization()(x)\n",
    "    x = Dense(512,activation='swish')(flatten)\n",
    "    norm = BatchNormalization()(x)\n",
    "    x = Dense(128,activation='relu')(norm)\n",
    "    norm = BatchNormalization()(x)\n",
    "    dropout = Dropout(0.2)(norm)\n",
    "    x = Dense(len(class_names))(dropout)\n",
    "    model = tf.keras.models.Model(inputs=input, outputs=x)\n",
    "\n",
    "    model.compile(optimizer=Adam(lr_init),\n",
    "              loss=scc(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "def schedule(epoch,lr):\n",
    "    if epoch < 5:\n",
    "        return ((epoch)+1)*lr_init/5\n",
    "    if epoch < 15:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "lr_scheduler = LearningRateScheduler(schedule,verbose=1)\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss=history.history['loss']\n",
    "    val_loss=history.history['val_loss']\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    base_model = base(input_shape=(image_size,image_size,3), include_top=False, weights='imagenet')\n",
    "    base_model.trainable = False\n",
    "    model = create_model(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0004.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 21:27:17.694576: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m14s\u001b[0m 15s/step - accuracy: 0.6653 - loss: 0.7711"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 22:29:43.970339: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15s/step - accuracy: 0.6654 - loss: 0.7705 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 22:29:45.771926: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2024-05-02 22:36:59.480106: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4191s\u001b[0m 16s/step - accuracy: 0.6656 - loss: 0.7700 - val_accuracy: 0.7808 - val_loss: 0.5378 - learning_rate: 4.0000e-04\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0008.\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 22:37:09.013648: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m138/251\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m27:03\u001b[0m 14s/step - accuracy: 0.7335 - loss: 0.5584"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=val_ds,\n",
    "                   callbacks=[es,lr_scheduler])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
